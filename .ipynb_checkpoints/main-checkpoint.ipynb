{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d270a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from Data_Clean_Room import data_clean_room\n",
    "import os\n",
    "from realtabformer import REaLTabFormer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wasserstein_distance as wd\n",
    "from scipy.stats import chisquare\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from SIMPRO import simpro\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from scipy.cluster import hierarchy\n",
    "import calendar\n",
    "import random\n",
    "import names\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa2bd4",
   "metadata": {},
   "source": [
    "# Define function to calculate the Cramer's V correlation matrix and convert the timestamp into categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94e307e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(x):\n",
    "        try:\n",
    "            pd.to_numeric(x)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "        \n",
    "def cramer_v(x, y):\n",
    "        confusion_matrix = pd.crosstab(x, y)\n",
    "        chi2, p, _, _ = scipy.stats.chi2_contingency(confusion_matrix)\n",
    "        n = confusion_matrix.sum().sum()\n",
    "        phi2 = chi2 / n\n",
    "        r, k = confusion_matrix.shape\n",
    "        phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) / (n - 1))\n",
    "        rcorr = r - ((r - 1) ** 2) / (n - 1)\n",
    "        kcorr = k - ((k - 1) ** 2) / (n - 1)\n",
    "        return np.sqrt(phi2corr / min((kcorr - 1), (rcorr - 1)))   \n",
    "    \n",
    "def divide_date(number):\n",
    "    # Parse the input date string\n",
    "    date_string = str(number)\n",
    "    date_object = datetime.strptime(date_string, '%Y%m%d%H%M')\n",
    "\n",
    "    # Extract year, month, day, hour, and minute\n",
    "    year = date_object.year\n",
    "    month = date_object.month\n",
    "    day = date_object.day\n",
    "    hour = date_object.strftime('%I')  # Convert hour to 12-hour format\n",
    "    minute = date_object.minute\n",
    "    am_pm = 1 if date_object.strftime('%p') == 'AM' else 0\n",
    "\n",
    "    return pd.Series([year, month, day, hour, minute, am_pm])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_date_column(df, column_name):\n",
    "    new_columns = df[column_name].apply(divide_date)\n",
    "    new_columns.columns = [f\"{column_name}_{i}\" for i in ['y', 'm', 'd', 'h', 'min', 'AM']]\n",
    "    return pd.concat([df.drop(columns=[column_name]), new_columns], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def combine_date(df, column_name):\n",
    "    cols = [f\"{column_name}_{i}\" for i in ['y', 'm', 'd', 'h', 'min', 'AM']]\n",
    "    combined_dates = []\n",
    "    for index, row in df.iterrows():\n",
    "        year = row[cols[0]]\n",
    "        month = row[cols[1]]\n",
    "        day = row[cols[2]]\n",
    "        if day == 0:\n",
    "            day += 1\n",
    "        hour = int(row[cols[3]])\n",
    "        minute = row[cols[4]]\n",
    "        if row[cols[5]] == 1:\n",
    "            if hour == 12:\n",
    "                hour = 0  # Midnight\n",
    "        else:\n",
    "            if hour != 12:\n",
    "                hour += 12  # Convert to 24-hour format if PM\n",
    "                \n",
    "        try:\n",
    "            combined_date = datetime(year, month, day, hour, minute)\n",
    "        except ValueError:\n",
    "            # If an invalid date is encountered, adjust to the nearest valid date\n",
    "            max_day = 31  # Assume maximum days in a month (adjust as necessary)\n",
    "            if month in [4, 6, 9, 11]:  # Months with 30 days\n",
    "                max_day = 30\n",
    "            elif month == 2:  # February handling (leap year not considered here)\n",
    "                max_day = 28\n",
    "            \n",
    "            if day > max_day:\n",
    "                day = max_day  # Adjust day to the last valid day of the month\n",
    "            \n",
    "            # Create a valid datetime object\n",
    "            combined_date = datetime(year, month, day, hour, minute)\n",
    "    combined_dates = pd.Series(combined_dates)\n",
    "    combined_dates.name = column_name\n",
    "    return pd.concat([df.drop(columns = cols), combined_dates], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1eeeaa",
   "metadata": {},
   "source": [
    "# Correlation Dimensional Reduction Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07f49275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_combine(c1, c2, key = 'user_id'):\n",
    "    c = pd.merge(c2, c1, left_on = key, right_on = key)\n",
    "    return c\n",
    "\n",
    "def cdr(c1, c2, key = 'user_id', corr = 0.1):\n",
    "    c = pd.merge(c2, c1, left_on = key, right_on = key)\n",
    "\n",
    "    special_col_list = [key]\n",
    "    normal_col_list = [key]\n",
    "    for col in c.columns:\n",
    "            if col != key:\n",
    "                if isinstance(c[col][0], str) and c[col].str.contains('^').any():\n",
    "                    special_col_list.append(col)\n",
    "                elif isinstance(c[col][0], datetime):\n",
    "                    special_col_list.append(col)\n",
    "                else:\n",
    "                    normal_col_list.append(col)\n",
    "\n",
    "    special_col = c[special_col_list].drop_duplicates()\n",
    "    normal_col = c[normal_col_list].drop_duplicates()\n",
    "\n",
    "    cor = np.zeros([len(normal_col.columns), len(normal_col.columns)])\n",
    "\n",
    "    for i in range(len(normal_col.columns)):\n",
    "        for j in range(len(normal_col.columns)):\n",
    "            cor[i, j] = cramer_v(normal_col.iloc[:, i], normal_col.iloc[:, j])\n",
    "\n",
    "    cor = pd.DataFrame(cor, index = normal_col.columns, columns = normal_col.columns)\n",
    "\n",
    "    independent_col_list = [key]\n",
    "    dependent_col_list = []\n",
    "    for col in normal_col.columns:\n",
    "        if all(cor[col].drop(col) <= corr):\n",
    "            independent_col_list.append(col)\n",
    "        else:\n",
    "            dependent_col_list.append(col)\n",
    "            \n",
    "    independent_col = c[independent_col_list].drop_duplicates()\n",
    "    dependent_col = c[dependent_col_list].drop_duplicates()\n",
    "    \n",
    "    child = dependent_col.copy()\n",
    "    \n",
    "    for col in independent_col:\n",
    "        new_col = []\n",
    "        for user_id in np.unique(child[key]):\n",
    "            new_col.extend(independent_col[independent_col[key] == user_id][col].sample(child[key].value_counts()[user_id], replace = True).values)\n",
    "        child[col] = new_col\n",
    "    \n",
    "\n",
    "    for col in special_col:\n",
    "        new_col = []\n",
    "        for user_id in np.unique(child[key]):\n",
    "            new_col.extend(special_col[special_col[key] == user_id][col].sample(child[key].value_counts()[user_id], replace = True).values)\n",
    "        child[col] = new_col\n",
    "    return child\n",
    "\n",
    "\n",
    "\n",
    "def cdr_hierarchical_cluster(c1, c2, key = 'user_id'):\n",
    "    c = pd.merge(c2, c1, left_on = key, right_on = key)\n",
    "\n",
    "    special_col_list = [key]\n",
    "    normal_col_list = [key]\n",
    "    for col in c.columns:\n",
    "            if col != key:\n",
    "                if isinstance(c[col][0], str) and c[col].str.contains('^').any():\n",
    "                    special_col_list.append(col)\n",
    "                elif isinstance(c[col][0], datetime):\n",
    "                    special_col_list.append(col)\n",
    "                else:\n",
    "                    normal_col_list.append(col)\n",
    "\n",
    "    special_col = c[special_col_list].drop_duplicates()\n",
    "    normal_col = c[normal_col_list].drop_duplicates()\n",
    "\n",
    "    cor = np.zeros([len(normal_col.columns), len(normal_col.columns)])\n",
    "\n",
    "    for i in range(len(normal_col.columns)):\n",
    "        for j in range(len(normal_col.columns)):\n",
    "            cor[i, j] = cramer_v(normal_col.iloc[:, i], normal_col.iloc[:, j])\n",
    "\n",
    "    cor = pd.DataFrame(cor, index = normal_col.columns, columns = normal_col.columns)\n",
    "    pdist = hierarchy.distance.pdist(cor)\n",
    "    linkage = hierarchy.linkage(pdist, method='average')\n",
    "    idx = hierarchy.fcluster(linkage, 0.5 * pdist.max(), 'distance')\n",
    "    order = []\n",
    "    subsets = {}\n",
    "    for i in range(len(np.unique(idx))):\n",
    "        if 'user_id' in cor.columns[np.where(idx == i + 1)[0]]:\n",
    "            subsets[f\"Subset_{i + 1}\"] = list(cor.columns[np.where(idx == i + 1)[0]])\n",
    "        else:\n",
    "            subsets[f\"Subset_{i + 1}\"] = ['user_id'] + list(cor.columns[np.where(idx == i + 1)[0]])\n",
    "\n",
    "    normal_col_subset = {}\n",
    "\n",
    "    for subset, subset_features in subsets.items():\n",
    "        normal_col_subset[subset] = normal_col[subset_features].drop_duplicates()\n",
    "\n",
    "    longest_dataframe_name = None\n",
    "    longest_dataframe_length = -1\n",
    "\n",
    "\n",
    "    for name, df in normal_col_subset.items():\n",
    "        current_length = len(df)\n",
    "        if current_length > longest_dataframe_length:\n",
    "            longest_dataframe_length = current_length\n",
    "            longest_dataframe_name = name\n",
    "\n",
    "    base_col = normal_col_subset[longest_dataframe_name].reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    additional_subsets = {}\n",
    "\n",
    "    for i in range(len(normal_col_subset) - 1):\n",
    "        if f\"Subset_{i + 1}\" != longest_dataframe_name:\n",
    "            subset_to_add = normal_col_subset[f\"Subset_{i + 1}\"]\n",
    "            new_df = []\n",
    "            for user_id in np.unique(base_col['user_id']):\n",
    "                new_df.extend(subset_to_add[subset_to_add['user_id'] == user_id].sample(base_col['user_id'].value_counts()[user_id], replace = True).values)\n",
    "                #base_col[col] = new_col \n",
    "            additional_subsets[i] = pd.DataFrame(new_df, columns = subset_to_add.columns)\n",
    "            \n",
    "            \n",
    "    for sub in additional_subsets.keys():\n",
    "        for col in additional_subsets[sub].columns:\n",
    "            if col != 'user_id':\n",
    "                base_col[col] = additional_subsets[sub][col]\n",
    "\n",
    "    child = base_col   \n",
    "    for col in special_col:\n",
    "        new_col = []\n",
    "        for user_id in np.unique(base_col['user_id']):\n",
    "            new_col.extend(special_col[special_col['user_id'] == user_id][col].sample(base_col['user_id'].value_counts()[user_id], replace = True).values)\n",
    "        child[col] = new_col\n",
    "    return child"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dac4fc",
   "metadata": {},
   "source": [
    "# Synthesis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30586c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize(parent, child, parent_n = 20, child_n = 200, join_on = 'user_id'):\n",
    "    parent_model = REaLTabFormer(model_type=\"tabular\", epochs = 1, batch_size = 5, train_size = 0.8)\n",
    "    parent_model.fit(parent.drop(join_on, axis=1), num_bootstrap=5)\n",
    "    \n",
    "    save_directory = f\"fine_tuned_model_demo\"\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "        \n",
    "    pdir = Path(save_directory)\n",
    "        \n",
    "    parent_model.save(pdir)\n",
    "    parent_model_path = sorted([p for p in pdir.glob(\"id*\") if p.is_dir()], key=os.path.getmtime)[-1]\n",
    "        \n",
    "    child_model_1 = REaLTabFormer(model_type=\"relational\",\n",
    "                    parent_realtabformer_path=parent_model_path, epochs=10, batch_size = 5, train_size = 0.8)\n",
    "        \n",
    "    child_model_1.fit(df = child,\n",
    "                    in_df = parent,\n",
    "                    join_on = join_on, num_bootstrap = 5)\n",
    "    \n",
    "    \n",
    "    parent_samples = parent_model.sample(parent_n)\n",
    "    parent_samples.index.name = join_on\n",
    "    parent_samples = parent_samples.reset_index()\n",
    "    \n",
    "    child_samples = child_model_1.sample(n_samples = child_n,\n",
    "                    input_unique_ids=parent_samples[join_on],\n",
    "                    input_df=parent_samples.drop(join_on, axis=1),\n",
    "                    output_max_length = None,\n",
    "                    gen_batch = 1)\n",
    "        \n",
    "    child_samples.index.name = join_on\n",
    "    return parent_samples, child_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f60322",
   "metadata": {},
   "source": [
    "# Corrlation Dimension Reduction Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94cad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ids = [10005, 10006, 14584, 22100, 31941, 31996, 34382, 34975]\n",
    "\n",
    "for task_id in task_ids:\n",
    "    torch.cuda.empty_cache()\n",
    "    d1 = pd.read_csv(f\"datasets/task_id_{task_id}/feeds.csv\")\n",
    "    d2 = pd.read_csv(f\"datasets/task_id_{task_id}/ads.csv\")\n",
    "    \n",
    "    \n",
    "    if task_id == 10006 or task_id == 22100:\n",
    "        d2 = d2.drop('ad_close_list_v001', axis = 1)\n",
    "        d2 = d2.drop('ad_close_list_v002', axis = 1)\n",
    "        d2 = d2.drop('ad_close_list_v003', axis = 1)\n",
    "        d2 = d2.drop('pt_d', axis = 1)\n",
    "        d1 = d1.drop('e_et', axis = 1)\n",
    "    else:\n",
    "        d1 = convert_date_column(d1, 'e_et')\n",
    "        d2 = convert_date_column(d2, 'pt_d')\n",
    "\n",
    "   \n",
    "    \n",
    "    if 'log_id' in d2.columns:\n",
    "        d2 = d2.drop('log_id', axis = 1)\n",
    "    \n",
    "    dcr = data_clean_room(d1, d2, 'user_id')\n",
    "    dcr.derec()\n",
    "    dcr.sampling(200)\n",
    "    \n",
    "    c1 = dcr.derec_child_1_small\n",
    "    c2 = dcr.derec_child_2_small\n",
    "    \n",
    "    # Extract the Parent Table with the DEREC pipeline \n",
    "    parent = dcr.derec_parent_small\n",
    "    \n",
    "    # Combine the remaining child tables with one of the correlation dimensional reduction method\n",
    "    child = cdr(c1, c2, 'user_id', 0.1)\n",
    "    #child = direct_combine(c1, c2, 'user_id')\n",
    "    #child = cdr_hierarchical_cluster(c1, c2, 'user_id')\n",
    "    \n",
    "    join_on = 'user_id'              \n",
    "        \n",
    "    # Synthesize data\n",
    "    parent_samples, child_samples = synthesize(parent, child, parent_n = 20, child_n = 200, join_on = join_on)\n",
    "    \n",
    "    # Refresh cuda memories\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Reverse the parent-child table structure back to input data structure\n",
    "    new_syn_child_1 = child_samples[[col for col in child_samples.columns if col in dcr.og1.columns]]\n",
    "    new_syn_child_2 = child_samples[[col for col in child_samples.columns if col in dcr.og2.columns]]\n",
    "    new_syn_parent_1 = parent_samples[[col for col in parent_samples.columns if col in dcr.og1.columns]]\n",
    "    new_syn_parent_2 = parent_samples[[col for col in parent_samples.columns if col in dcr.og2.columns]]\n",
    "    \n",
    "    new_syn_1 = pd.merge(new_syn_parent_1, new_syn_child_1, left_on = 'user_id', right_on = 'user_id')\n",
    "    new_syn_2 = pd.merge(new_syn_parent_2, new_syn_child_2, left_on = 'user_id', right_on = 'user_id')\n",
    "    \n",
    "\n",
    "    og_parent = dcr.derec_parent_small\n",
    "    og_1_p = og_parent[[col for col in parent_samples.columns if col in dcr.og1.columns]]\n",
    "    og_2_p = og_parent[[col for col in parent_samples.columns if col in dcr.og2.columns]]\n",
    "    \n",
    "    og_1 = pd.merge(og_1_p, c1, left_on = 'user_id', right_on = 'user_id')\n",
    "    og_2 = pd.merge(og_2_p, c2, left_on = 'user_id', right_on = 'user_id')\n",
    "    \n",
    "    og_1 = og_1[list(new_syn_1.columns)]\n",
    "    og_2 = og_2[list(new_syn_2.columns)]\n",
    "    \n",
    "    \n",
    "    dcr.synthesize(20, 200)\n",
    "    \n",
    "    old_syn_1 = dcr.syn1\n",
    "    old_syn_2 = dcr.syn2\n",
    "    \n",
    "    old_syn_1 = old_syn_1[list(new_syn_1.columns)]\n",
    "    old_syn_2 = old_syn_2[list(new_syn_2.columns)] \n",
    "    \n",
    "    \n",
    "    if task_id != 10006 and task_id != 22100:\n",
    "        new_syn_1 = combine_date(new_syn_1, 'e_et')\n",
    "        new_syn_2 = combine_date(new_syn_2, 'pt_d')\n",
    "\n",
    "        old_syn_1 = combine_date(old_syn_1, 'e_et')\n",
    "        old_syn_2 = combine_date(old_syn_2, 'pt_d')\n",
    "\n",
    "        og_1 = combine_date(og_1, 'e_et')\n",
    "        og_2 = combine_date(og_2, 'pt_d')\n",
    "    \n",
    "    \n",
    "    og = {}\n",
    "    og['d1'] = og_1\n",
    "    og['d2'] = og_2\n",
    "    \n",
    "    old = {}\n",
    "    old['d1'] = old_syn_1\n",
    "    old['d2'] = old_syn_2\n",
    "    \n",
    "    new = {}\n",
    "    new['d1'] = new_syn_1\n",
    "    new['d2'] = new_syn_2\n",
    "    \n",
    "    old_evaluation = simpro(og, old)\n",
    "    old_evaluation.cal_marginal_indicators()\n",
    "    old_evaluation.cal_conditional_indicators()\n",
    "    \n",
    "    new_evaluation = simpro(og, new)\n",
    "    new_evaluation.cal_marginal_indicators()\n",
    "    new_evaluation.cal_conditional_indicators()\n",
    "    \n",
    "    old_p = old_evaluation.conditional_indicators['p-values']\n",
    "    new_p = new_evaluation.conditional_indicators['p-values']\n",
    "    old_w = old_evaluation.conditional_indicators['w-distance']\n",
    "    new_w = new_evaluation.conditional_indicators['w-distance']\n",
    "    \n",
    "    p_val = pd.DataFrame([old_p, new_p], index = ['Old', 'New']).T\n",
    "    p_val = p_val.fillna(1)\n",
    "    p_val.to_csv(f\"results/p_val_{task_id}_cdr.csv\")\n",
    "    \n",
    "    w_dis = pd.DataFrame([old_w, new_w], index = ['Old', 'New']).T\n",
    "    w_dis.to_csv(f\"results/w_dis_{task_id}_cdr.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d69e9",
   "metadata": {},
   "source": [
    "# Automatic Transforming Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84623fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class qualitative_transformer:\n",
    "    def __init__(self, df, col_names):\n",
    "        self.df = df.copy()\n",
    "        self.col_names = col_names\n",
    "        self.all_inv_maps = None\n",
    "        self.all_maps = None\n",
    "        \n",
    "    def generate_list_of_names(self, n):\n",
    "        name_list = []\n",
    "        while len(name_list) < n:\n",
    "            name_list.append(names.get_first_name())\n",
    "            name_list = list(set(name_list))\n",
    "        return list(set(name_list))\n",
    "    \n",
    "    def remove_elements(self, original_list, elements_to_remove):\n",
    "        return [x for x in original_list if x not in elements_to_remove]\n",
    "    \n",
    "    def create_map(self):\n",
    "        N = 0\n",
    "        for col_name in self.col_names:\n",
    "            N += len(np.unique(self.df[col_name]))\n",
    "        name_list = self.generate_list_of_names(N)\n",
    "        self.all_maps = {}\n",
    "        for col_name in self.col_names:\n",
    "            col_map = {}\n",
    "            col_pool = random.sample(name_list, len(np.unique(self.df[col_name])))\n",
    "            j = 0\n",
    "            for i in np.unique(self.df[col_name]):\n",
    "                col_map[i] = col_pool[j]\n",
    "                j += 1\n",
    "            name_list = self.remove_elements(name_list, col_pool)\n",
    "            self.all_maps[col_name] = col_map\n",
    "        \n",
    "        self.all_inv_maps = {}\n",
    "        for col_name in self.col_names:\n",
    "            self.all_inv_maps[col_name] = {v: k for k, v in self.all_maps[col_name].items()}\n",
    "            \n",
    "            \n",
    "    def transform(self, new_df):\n",
    "        if self.all_maps == None:\n",
    "            self.create_map()\n",
    "        output_df = new_df.copy()\n",
    "        for col_name in self.col_names:\n",
    "            output_df[col_name] = output_df[col_name].map(self.all_maps[col_name])\n",
    "        return output_df\n",
    "            \n",
    "            \n",
    "    def inv_transform(self, new_df):\n",
    "        output_df = new_df.copy()\n",
    "        for col_name in self.col_names:\n",
    "            output_df[col_name] = output_df[col_name].map(self.all_inv_maps[col_name])\n",
    "        return output_df\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56290dd6",
   "metadata": {},
   "source": [
    "# Automatic Categorical Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c7c5634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the sensitivity threshold...\n",
      "Using parallel computation!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:570: UserWarning: Duplicate rate (0.0) in the data is zero. The `qt_interval` will be set                     to qt_interval_unique=100.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:597: UserWarning: qt_interval adjusted from 100 to 2...\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5285c11a6644a23bb1cc7c22e1e4b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap round:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity threshold summary:\n",
      "count    5.000000\n",
      "mean     0.014394\n",
      "std      0.012677\n",
      "min     -0.006818\n",
      "25%      0.014394\n",
      "50%      0.017424\n",
      "75%      0.020455\n",
      "max      0.026515\n",
      "dtype: float64\n",
      "Sensitivity threshold: 0.0253030303030303 qt_max: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d345d998864e339965ccb32cb25ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:482: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthomask1018\u001b[0m (\u001b[33mthomask1018-adaptive-investment-solutions\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\thoma\\Downloads\\Research\\KDD_GReaTER_submission\\wandb\\run-20240804_173711-odu2eo4t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thomask1018-adaptive-investment-solutions/huggingface/runs/odu2eo4t' target=\"_blank\">rtf_checkpoints</a></strong> to <a href='https://wandb.ai/thomask1018-adaptive-investment-solutions/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thomask1018-adaptive-investment-solutions/huggingface' target=\"_blank\">https://wandb.ai/thomask1018-adaptive-investment-solutions/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thomask1018-adaptive-investment-solutions/huggingface/runs/odu2eo4t' target=\"_blank\">https://wandb.ai/thomask1018-adaptive-investment-solutions/huggingface/runs/odu2eo4t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:650: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d2131f82c944a9802faeb1c253c477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n",
      "Critic round: 5,                     sensitivity_threshold: 0.0253030303030303,                         val_sensitivity: -0.0241919191919192,                             val_sensitivities: [-0.025, -0.025, -0.025, -0.01893939393939394, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.01893939393939394, -0.025, -0.025, -0.025, -0.025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:839: UserWarning: No best model was saved. Loading the closest model to the sensitivity_threshold.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying artefacts from: best-disc-model\n",
      "Copying artefacts from: mean-best-disc-model\n",
      "Copying artefacts from: not-best-disc-model\n",
      "Copying artefacts from: last-epoch-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:177: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(parent_realtabformer_path / ModelFileName.rtf_model_pt)\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:313: UserWarning: A trained model for the parent table is available. The encoder will use the                     pretrained config and weights.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64823001f7fa4d498a08f19d738a89a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35468 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf67591fad94c21a57bed702c27336b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ec43855852479bb94643b814e81808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:765: UserWarning: A total of 195 out of 200 has been removed from the training data because they exceeded the `output_max_length` of 512.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c27d290bac489495b5f3ece2f917fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:482: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652a5542b1d249338cd266c237afcff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083d55b0331a467fa7eb369546c8dd14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156e325692c646418b91ac87a0077898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the sensitivity threshold...\n",
      "Using parallel computation!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:570: UserWarning: Duplicate rate (0.0) in the data is zero. The `qt_interval` will be set                     to qt_interval_unique=100.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:597: UserWarning: qt_interval adjusted from 100 to 2...\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f348451ee192466aa1bfcde21f6113f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap round:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity threshold summary:\n",
      "count    5.000000\n",
      "mean    -0.005000\n",
      "std      0.018383\n",
      "min     -0.025000\n",
      "25%     -0.015909\n",
      "50%     -0.006818\n",
      "75%     -0.000758\n",
      "max      0.023485\n",
      "dtype: float64\n",
      "Sensitivity threshold: 0.01863636363636363 qt_max: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a1b200a77a4d83a2ceb947528d27b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:482: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9715d45bcd8a4569998d45a13d7d1775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n",
      "Critic round: 5,                     sensitivity_threshold: 0.01863636363636363,                         val_sensitivity: -0.0241919191919192,                             val_sensitivities: [-0.025, -0.025, -0.025, -0.01893939393939394, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.01893939393939394, -0.025, -0.025, -0.025, -0.025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:839: UserWarning: No best model was saved. Loading the closest model to the sensitivity_threshold.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying artefacts from: best-disc-model\n",
      "Copying artefacts from: mean-best-disc-model\n",
      "Copying artefacts from: not-best-disc-model\n",
      "Copying artefacts from: last-epoch-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:177: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(parent_realtabformer_path / ModelFileName.rtf_model_pt)\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:313: UserWarning: A trained model for the parent table is available. The encoder will use the                     pretrained config and weights.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31827775b654a18955feb6bd37a92aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17940 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8f2681873b43138220aee1c5e34fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00d5af83f0e45fb8320aa83e75745e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:765: UserWarning: A total of 187 out of 200 has been removed from the training data because they exceeded the `output_max_length` of 512.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc191197e3b34585b32a7afd614587d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:482: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c906a127041d43578d5168fdc34aa061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a039405bf24e1ca3dba5a82dcbe59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2bf085fd9b4ec28a4524f2b8f8a107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the sensitivity threshold...\n",
      "Using parallel computation!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:570: UserWarning: Duplicate rate (0.0) in the data is zero. The `qt_interval` will be set                     to qt_interval_unique=100.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:597: UserWarning: qt_interval adjusted from 100 to 2...\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa6fa1a42a64dd690d9eeea9747c876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap round:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity threshold summary:\n",
      "count    5.000000\n",
      "mean     0.004091\n",
      "std      0.019709\n",
      "min     -0.012879\n",
      "25%     -0.012879\n",
      "50%     -0.003788\n",
      "75%      0.020455\n",
      "max      0.029545\n",
      "dtype: float64\n",
      "Sensitivity threshold: 0.027727272727272725 qt_max: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d5889571ef4d5ea6c18108d7e24541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:482: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51688a296aae484f8d0fb621810d3b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n",
      "Critic round: 5,                     sensitivity_threshold: 0.027727272727272725,                         val_sensitivity: -0.0241919191919192,                             val_sensitivities: [-0.025, -0.025, -0.025, -0.01893939393939394, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.01893939393939394, -0.025, -0.025, -0.025, -0.025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:839: UserWarning: No best model was saved. Loading the closest model to the sensitivity_threshold.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying artefacts from: best-disc-model\n",
      "Copying artefacts from: mean-best-disc-model\n",
      "Copying artefacts from: not-best-disc-model\n",
      "Copying artefacts from: last-epoch-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:177: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(parent_realtabformer_path / ModelFileName.rtf_model_pt)\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:313: UserWarning: A trained model for the parent table is available. The encoder will use the                     pretrained config and weights.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399e9ba6e7b84851aa3130b6aa9d5419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99414cfc32d7446683644a5be5fb7e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3e2e8719f0438f81a98c121b7b2ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c05838f3d64fa59daf16bb343980b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:482: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68043595cd004c3b9e2682484927463b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n",
      "C:\\Users\\thoma\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:152: UserWarning: Default values will be overridden because transform_data was passed...\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69845bf4245494ab4be88bbb306576e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fda85afe0934cafae9276c90f029f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1936/1936 [04:50<00:00,  6.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1936/1936 [04:38<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the sensitivity threshold...\n",
      "Using parallel computation!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73017be687144359ad68f27259c7f506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap round:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity threshold summary:\n",
      "count    5.000000\n",
      "mean    -0.003182\n",
      "std      0.015804\n",
      "min     -0.025000\n",
      "25%     -0.012879\n",
      "50%     -0.000758\n",
      "75%      0.011364\n",
      "max      0.011364\n",
      "dtype: float64\n",
      "Sensitivity threshold: 0.011363636363636364 qt_max: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a799e0f4634157adfaeb130ba5dba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e40bfd772c24373bd0982b15a81fceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n",
      "Critic round: 5,                     sensitivity_threshold: 0.011363636363636364,                         val_sensitivity: -0.021969696969696972,                             val_sensitivities: [-0.01590909090909091, -0.01893939393939394, -0.025, -0.01893939393939394, -0.025, -0.025, -0.0068181818181818205, -0.025, -0.025, -0.025, -0.025, -0.025, -0.01893939393939394, -0.025, -0.025]\n",
      "Copying artefacts from: best-disc-model\n",
      "Copying artefacts from: mean-best-disc-model\n",
      "Copying artefacts from: not-best-disc-model\n",
      "Copying artefacts from: last-epoch-model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce387db37404f7389ca6a77160198f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m join_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m              \n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m###\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m parent_samples, child_samples \u001b[38;5;241m=\u001b[39m synthesize(parent, child, parent_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, child_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m, join_on \u001b[38;5;241m=\u001b[39m join_on)\n\u001b[0;32m     46\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m     48\u001b[0m new_syn_child_1 \u001b[38;5;241m=\u001b[39m child_samples[[col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m child_samples\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m dcr\u001b[38;5;241m.\u001b[39mog1\u001b[38;5;241m.\u001b[39mcolumns]]\n",
      "Cell \u001b[1;32mIn[24], line 17\u001b[0m, in \u001b[0;36msynthesize\u001b[1;34m(parent, child, parent_n, child_n, join_on)\u001b[0m\n\u001b[0;32m     12\u001b[0m parent_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pdir\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid*\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mis_dir()], key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetmtime)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     14\u001b[0m child_model_1 \u001b[38;5;241m=\u001b[39m REaLTabFormer(model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelational\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m                 parent_realtabformer_path\u001b[38;5;241m=\u001b[39mparent_model_path, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m child_model_1\u001b[38;5;241m.\u001b[39mfit(df \u001b[38;5;241m=\u001b[39m child,\n\u001b[0;32m     18\u001b[0m                 in_df \u001b[38;5;241m=\u001b[39m parent,\n\u001b[0;32m     19\u001b[0m                 join_on \u001b[38;5;241m=\u001b[39m join_on, num_bootstrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     22\u001b[0m parent_samples \u001b[38;5;241m=\u001b[39m parent_model\u001b[38;5;241m.\u001b[39msample(parent_n)\n\u001b[0;32m     23\u001b[0m parent_samples\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m join_on\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:490\u001b[0m, in \u001b[0;36mREaLTabFormer.fit\u001b[1;34m(self, df, in_df, join_on, resume_from_checkpoint, device, num_bootstrap, frac, frac_max_data, qt_max, qt_max_default, qt_interval, qt_interval_unique, distance, quantile, n_critic, n_critic_stop, gen_rounds, sensitivity_max_col_nums, use_ks, full_sensitivity, sensitivity_orig_frac_multiple, orig_samples_rounds, load_from_best_mean_sensitivity, target_col)\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    486\u001b[0m         in_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    487\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe REaLTabFormer for relational data requires two tables for training.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m join_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe column to join the data must not be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 490\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_relational(df, in_df, join_on\u001b[38;5;241m=\u001b[39mjoin_on, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    491\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain(resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint)\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:962\u001b[0m, in \u001b[0;36mREaLTabFormer._fit_relational\u001b[1;34m(self, out_df, in_df, join_on, device)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_vocab\n\u001b[0;32m    961\u001b[0m \u001b[38;5;66;03m# Load the dataframe into a HuggingFace Dataset\u001b[39;00m\n\u001b[1;32m--> 962\u001b[0m dataset \u001b[38;5;241m=\u001b[39m make_relational_dataset(\n\u001b[0;32m    963\u001b[0m     in_df\u001b[38;5;241m=\u001b[39min_df,\n\u001b[0;32m    964\u001b[0m     out_df\u001b[38;5;241m=\u001b[39mout_df,\n\u001b[0;32m    965\u001b[0m     vocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab,\n\u001b[0;32m    966\u001b[0m     in_out_idx\u001b[38;5;241m=\u001b[39min_out_idx,\n\u001b[0;32m    967\u001b[0m     output_max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_max_length,\n\u001b[0;32m    968\u001b[0m     mask_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_rate,\n\u001b[0;32m    969\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    970\u001b[0m )\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# Compute the longest sequence of labels in the dataset and add a buffer of 1.\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelational_max_length \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    975\u001b[0m         dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m example: \u001b[38;5;28mdict\u001b[39m(length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])))[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    980\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\realtabformer\\data_utils.py:724\u001b[0m, in \u001b[0;36mmake_relational_dataset\u001b[1;34m(in_df, out_df, vocab, in_out_idx, mask_rate, output_max_length, return_token_type_ids)\u001b[0m\n\u001b[0;32m    721\u001b[0m decoder_dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_pandas(out_df, preserve_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;66;03m# Do not add [BOS] and [EOS] here. This will be handled\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;66;03m# in the creation of the training_dataset in `get_relational_input_ids`.\u001b[39;00m\n\u001b[1;32m--> 724\u001b[0m decoder_dataset \u001b[38;5;241m=\u001b[39m decoder_dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m example: get_input_ids(\n\u001b[0;32m    726\u001b[0m         example,\n\u001b[0;32m    727\u001b[0m         vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    728\u001b[0m         out_df\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m    729\u001b[0m         mask_rate\u001b[38;5;241m=\u001b[39mmask_rate,\n\u001b[0;32m    730\u001b[0m         return_label_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    731\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    732\u001b[0m         affix_bos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    733\u001b[0m         affix_eos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    734\u001b[0m     ),\n\u001b[0;32m    735\u001b[0m     remove_columns\u001b[38;5;241m=\u001b[39mdecoder_dataset\u001b[38;5;241m.\u001b[39mcolumn_names,\n\u001b[0;32m    736\u001b[0m )\n\u001b[0;32m    738\u001b[0m training_dataset \u001b[38;5;241m=\u001b[39m encoder_dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m example, idx: get_relational_input_ids(\n\u001b[0;32m    740\u001b[0m         example,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    749\u001b[0m     with_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    750\u001b[0m )\n\u001b[0;32m    752\u001b[0m \u001b[38;5;66;03m# If the output_max_length variable is specified, filter\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# observations that exceed this length. The\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# `get_relational_input_ids` should have set the\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;66;03m# `labels` to None if the output exceeds `output_max_length`.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    565\u001b[0m }\n\u001b[0;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py:3161\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3156\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3157\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3158\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3159\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3160\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3161\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3162\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3163\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py:3538\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3536\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite_row(example\u001b[38;5;241m.\u001b[39mto_arrow())\n\u001b[0;32m   3537\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3538\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite(example)\n\u001b[0;32m   3539\u001b[0m num_examples_progress_update \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m _time \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mPBAR_REFRESH_TIME_INTERVAL:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_writer.py:500\u001b[0m, in \u001b[0;36mArrowWriter.write\u001b[1;34m(self, example, key, writer_batch_size)\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;66;03m# Re-intializing to empty list for next batch\u001b[39;00m\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhkey_record \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 500\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_examples_on_file()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_writer.py:458\u001b[0m, in \u001b[0;36mArrowWriter.write_examples_on_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    454\u001b[0m         batch_examples[col] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    455\u001b[0m             row[\u001b[38;5;241m0\u001b[39m][col]\u001b[38;5;241m.\u001b[39mto_pylist()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row[\u001b[38;5;241m0\u001b[39m][col], (pa\u001b[38;5;241m.\u001b[39mArray, pa\u001b[38;5;241m.\u001b[39mChunkedArray)) \u001b[38;5;28;01melse\u001b[39;00m row[\u001b[38;5;241m0\u001b[39m][col]\n\u001b[0;32m    456\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples\n\u001b[0;32m    457\u001b[0m         ]\n\u001b[1;32m--> 458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_batch(batch_examples\u001b[38;5;241m=\u001b[39mbatch_examples)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_writer.py:569\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[1;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[0;32m    567\u001b[0m         typed_sequence \u001b[38;5;241m=\u001b[39m OptimizedTypedSequence(col_values, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mcol_type, try_type\u001b[38;5;241m=\u001b[39mcol_try_type, col\u001b[38;5;241m=\u001b[39mcol)\n\u001b[0;32m    568\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(pa\u001b[38;5;241m.\u001b[39marray(typed_sequence))\n\u001b[1;32m--> 569\u001b[0m         inferred_features[col] \u001b[38;5;241m=\u001b[39m typed_sequence\u001b[38;5;241m.\u001b[39mget_inferred_type()\n\u001b[0;32m    570\u001b[0m schema \u001b[38;5;241m=\u001b[39m inferred_features\u001b[38;5;241m.\u001b[39marrow_schema \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n\u001b[0;32m    571\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_arrays(arrays, schema\u001b[38;5;241m=\u001b[39mschema)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_writer.py:133\u001b[0m, in \u001b[0;36mTypedSequence.get_inferred_type\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the inferred feature type.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03mThis is done by converting the sequence to an Arrow array, and getting the corresponding\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03mfeature type.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    FeatureType: inferred feature type of the sequence.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type \u001b[38;5;241m=\u001b[39m generate_from_arrow_type(pa\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtype)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\array.pxi:247\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\array.pxi:112\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_writer.py:208\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# otherwise we can finally use the user's type\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;66;03m# We use cast_array_to_feature to support casting to custom types like Audio and Image\u001b[39;00m\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;66;03m# Also, when trying type \"string\", we don't want to convert integers or floats to \"string\".\u001b[39;00m\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;66;03m# We only do it if trying_type is False - since this is what the user asks for.\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m         out \u001b[38;5;241m=\u001b[39m cast_array_to_feature(\n\u001b[0;32m    209\u001b[0m             out, \u001b[38;5;28mtype\u001b[39m, allow_primitive_to_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrying_type, allow_decimal_to_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrying_type\n\u001b[0;32m    210\u001b[0m         )\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;167;01mTypeError\u001b[39;00m,\n\u001b[0;32m    214\u001b[0m     pa\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[0;32m    215\u001b[0m     pa\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    216\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# handle type errors and overflows\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# Ignore ArrowNotImplementedError caused by trying type, otherwise re-raise\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\table.py:1804\u001b[0m, in \u001b[0;36m_wrap_for_chunked_arrays.<locals>.wrapper\u001b[1;34m(array, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mchunked_array([func(chunk, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m array\u001b[38;5;241m.\u001b[39mchunks])\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(array, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\table.py:2075\u001b[0m, in \u001b[0;36mcast_array_to_feature\u001b[1;34m(array, feature, allow_primitive_to_str, allow_decimal_to_str)\u001b[0m\n\u001b[0;32m   2073\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mFixedSizeListArray\u001b[38;5;241m.\u001b[39mfrom_arrays(_c(array_values, feature\u001b[38;5;241m.\u001b[39mfeature), feature\u001b[38;5;241m.\u001b[39mlength)\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2075\u001b[0m     casted_array_values \u001b[38;5;241m=\u001b[39m _c(array\u001b[38;5;241m.\u001b[39mvalues, feature\u001b[38;5;241m.\u001b[39mfeature)\n\u001b[0;32m   2076\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m casted_array_values\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m array\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtype:\n\u001b[0;32m   2077\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m array\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\table.py:1804\u001b[0m, in \u001b[0;36m_wrap_for_chunked_arrays.<locals>.wrapper\u001b[1;34m(array, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mchunked_array([func(chunk, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m array\u001b[38;5;241m.\u001b[39mchunks])\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(array, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\table.py:2116\u001b[0m, in \u001b[0;36mcast_array_to_feature\u001b[1;34m(array, feature, allow_primitive_to_str, allow_decimal_to_str)\u001b[0m\n\u001b[0;32m   2109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array_cast(\n\u001b[0;32m   2110\u001b[0m         array,\n\u001b[0;32m   2111\u001b[0m         get_nested_type(feature),\n\u001b[0;32m   2112\u001b[0m         allow_primitive_to_str\u001b[38;5;241m=\u001b[39mallow_primitive_to_str,\n\u001b[0;32m   2113\u001b[0m         allow_decimal_to_str\u001b[38;5;241m=\u001b[39mallow_decimal_to_str,\n\u001b[0;32m   2114\u001b[0m     )\n\u001b[0;32m   2115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature, (Sequence, \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m-> 2116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array_cast(\n\u001b[0;32m   2117\u001b[0m         array,\n\u001b[0;32m   2118\u001b[0m         feature(),\n\u001b[0;32m   2119\u001b[0m         allow_primitive_to_str\u001b[38;5;241m=\u001b[39mallow_primitive_to_str,\n\u001b[0;32m   2120\u001b[0m         allow_decimal_to_str\u001b[38;5;241m=\u001b[39mallow_decimal_to_str,\n\u001b[0;32m   2121\u001b[0m     )\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt cast array of type\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(array\u001b[38;5;241m.\u001b[39mtype)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mto\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(feature)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\table.py:1804\u001b[0m, in \u001b[0;36m_wrap_for_chunked_arrays.<locals>.wrapper\u001b[1;34m(array, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mchunked_array([func(chunk, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m array\u001b[38;5;241m.\u001b[39mchunks])\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(array, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\table.py:1963\u001b[0m, in \u001b[0;36marray_cast\u001b[1;34m(array, pa_type, allow_primitive_to_str, allow_decimal_to_str)\u001b[0m\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_null(pa_type) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_null(array\u001b[38;5;241m.\u001b[39mtype):\n\u001b[0;32m   1962\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt cast array of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_short_str(array\u001b[38;5;241m.\u001b[39mtype)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_short_str(pa_type)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array\u001b[38;5;241m.\u001b[39mcast(pa_type)\n\u001b[0;32m   1964\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt cast array of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_short_str(array\u001b[38;5;241m.\u001b[39mtype)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_short_str(pa_type)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\array.pxi:985\u001b[0m, in \u001b[0;36mpyarrow.lib.Array.cast\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\compute.py:404\u001b[0m, in \u001b[0;36mcast\u001b[1;34m(arr, target_type, safe, options, memory_pool)\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         options \u001b[38;5;241m=\u001b[39m CastOptions\u001b[38;5;241m.\u001b[39msafe(target_type)\n\u001b[1;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcast\u001b[39m\u001b[38;5;124m\"\u001b[39m, [arr], options, memory_pool)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "task_ids = [10005, 10006, 14584, 22100, 31941, 31996, 34382, 34975]\n",
    "\n",
    "for task_id in task_ids:\n",
    "    torch.cuda.empty_cache()\n",
    "    d1 = pd.read_csv(f\"datasets/task_id_{task_id}/feeds.csv\")\n",
    "    d2 = pd.read_csv(f\"datasets/task_id_{task_id}/ads.csv\")\n",
    "    \n",
    "    \n",
    "    if task_id == 10006 or task_id == 22100:\n",
    "        d2 = d2.drop('ad_close_list_v001', axis = 1)\n",
    "        d2 = d2.drop('ad_close_list_v002', axis = 1)\n",
    "        d2 = d2.drop('ad_close_list_v003', axis = 1)\n",
    "        d2 = d2.drop('pt_d', axis = 1)\n",
    "        d1 = d1.drop('e_et', axis = 1)\n",
    "    else:\n",
    "        d1 = convert_date_column(d1, 'e_et')\n",
    "        d2 = convert_date_column(d2, 'pt_d')\n",
    "    \n",
    "    # Use map function to replace numeric values with categorical terms\n",
    "    transformer = qualitative_transformer(d2, ['age', 'gender', 'residence'])\n",
    "    d2 = transformer.transform(d2)\n",
    "    \n",
    "    \n",
    "    if 'log_id' in d2.columns:\n",
    "        d2 = d2.drop('log_id', axis = 1)\n",
    "    \n",
    "    dcr = data_clean_room(d1, d2, 'user_id')\n",
    "    dcr.derec()\n",
    "    dcr.sampling(200)\n",
    "    \n",
    "    c1 = dcr.derec_child_1_small\n",
    "    c2 = dcr.derec_child_2_small\n",
    "    \n",
    "    # Extract the Parent Table with the DEREC pipeline \n",
    "    parent = dcr.derec_parent_small\n",
    "    # Combine the remaining child tables with one of the correlation dimensional reduction method\n",
    "    child = cdr(c1, c2, 'user_id', 0.1)\n",
    "    #child = direct_combine(c1, c2, 'user_id')\n",
    "    #child = cdr_hierarchical_cluster(c1, c2, 'user_id')\n",
    "    \n",
    "    join_on = 'user_id'              \n",
    "        \n",
    "    ###\n",
    "    parent_samples, child_samples = synthesize(parent, child, parent_n = 20, child_n = 200, join_on = join_on)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    new_syn_child_1 = child_samples[[col for col in child_samples.columns if col in dcr.og1.columns]]\n",
    "    new_syn_child_2 = child_samples[[col for col in child_samples.columns if col in dcr.og2.columns]]\n",
    "    new_syn_parent_1 = parent_samples[[col for col in parent_samples.columns if col in dcr.og1.columns]]\n",
    "    new_syn_parent_2 = parent_samples[[col for col in parent_samples.columns if col in dcr.og2.columns]]\n",
    "    \n",
    "    new_syn_1 = pd.merge(new_syn_parent_1, new_syn_child_1, left_on = 'user_id', right_on = 'user_id')\n",
    "    new_syn_2 = pd.merge(new_syn_parent_2, new_syn_child_2, left_on = 'user_id', right_on = 'user_id')\n",
    "    \n",
    "    \n",
    "    d2 = transformer.inv_transform(d2)\n",
    "    new_syn_2 = transformer.inv_transform(new_syn_2)\n",
    "\n",
    "\n",
    "    \n",
    "    og_parent = dcr.derec_parent_small\n",
    "    og_1_p = og_parent[[col for col in parent_samples.columns if col in dcr.og1.columns]]\n",
    "    og_2_p = og_parent[[col for col in parent_samples.columns if col in dcr.og2.columns]]\n",
    "    \n",
    "    og_1 = pd.merge(og_1_p, c1, left_on = 'user_id', right_on = 'user_id')\n",
    "    og_2 = pd.merge(og_2_p, c2, left_on = 'user_id', right_on = 'user_id')\n",
    "    \n",
    "    og_1 = og_1[list(new_syn_1.columns)]\n",
    "    og_2 = og_2[list(new_syn_2.columns)]\n",
    "    \n",
    "    og_2 = transformer.inv_transform(og_2)\n",
    "\n",
    "\n",
    "    \n",
    "    dcr.synthesize(20, 200)\n",
    "    \n",
    "    old_syn_1 = dcr.syn1\n",
    "    old_syn_2 = dcr.syn2\n",
    "    \n",
    "    old_syn_1 = old_syn_1[list(new_syn_1.columns)]\n",
    "    old_syn_2 = old_syn_2[list(new_syn_2.columns)]\n",
    "    \n",
    "    old_syn_2 = transformer.inv_transform(old_syn_2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if task_id != 10006 and task_id != 22100:\n",
    "        new_syn_1 = combine_date(new_syn_1, 'e_et')\n",
    "        new_syn_2 = combine_date(new_syn_2, 'pt_d')\n",
    "\n",
    "        old_syn_1 = combine_date(old_syn_1, 'e_et')\n",
    "        old_syn_2 = combine_date(old_syn_2, 'pt_d')\n",
    "\n",
    "        og_1 = combine_date(og_1, 'e_et')\n",
    "        og_2 = combine_date(og_2, 'pt_d')\n",
    "    \n",
    "    \n",
    "    og = {}\n",
    "    og['d1'] = og_1\n",
    "    og['d2'] = og_2\n",
    "    \n",
    "    old = {}\n",
    "    old['d1'] = old_syn_1\n",
    "    old['d2'] = old_syn_2\n",
    "    \n",
    "    new = {}\n",
    "    new['d1'] = new_syn_1\n",
    "    new['d2'] = new_syn_2\n",
    "    \n",
    "    old_evaluation = simpro(og, old)\n",
    "    old_evaluation.cal_marginal_indicators()\n",
    "    old_evaluation.cal_conditional_indicators()\n",
    "    \n",
    "    new_evaluation = simpro(og, new)\n",
    "    new_evaluation.cal_marginal_indicators()\n",
    "    new_evaluation.cal_conditional_indicators()\n",
    "    \n",
    "    old_p = old_evaluation.conditional_indicators['p-values']\n",
    "    new_p = new_evaluation.conditional_indicators['p-values']\n",
    "    old_w = old_evaluation.conditional_indicators['w-distance']\n",
    "    new_w = new_evaluation.conditional_indicators['w-distance']\n",
    "    \n",
    "    p_val = pd.DataFrame([old_p, new_p], index = ['Old', 'New']).T\n",
    "    p_val = p_val.fillna(1)\n",
    "    p_val.to_csv(f\"results/p_val_{task_id}_auto_mapping_reduction.csv\")\n",
    "    \n",
    "    w_dis = pd.DataFrame([old_w, new_w], index = ['Old', 'New']).T\n",
    "    w_dis.to_csv(f\"results/w_dis_{task_id}_auto_mapping_reduction.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2a3381",
   "metadata": {},
   "source": [
    "# Manual Categorical Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4211a554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the sensitivity threshold...\n",
      "Using parallel computation!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d80f1a7a1e4b258307bd7de55bf505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap round:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity threshold summary:\n",
      "count    5.000000\n",
      "mean     0.031970\n",
      "std      0.049995\n",
      "min     -0.006818\n",
      "25%     -0.003788\n",
      "50%      0.008333\n",
      "75%      0.050758\n",
      "max      0.111364\n",
      "dtype: float64\n",
      "Sensitivity threshold: 0.09924242424242423 qt_max: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc14b4ab4164867b756e6e00d341e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6148342834fd4d24a72f4930cdce3f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n",
      "Critic round: 5,                     sensitivity_threshold: 0.09924242424242423,                         val_sensitivity: -0.0241919191919192,                             val_sensitivities: [-0.025, -0.025, -0.025, -0.01893939393939394, -0.01893939393939394, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025]\n",
      "Copying artefacts from: best-disc-model\n",
      "Copying artefacts from: mean-best-disc-model\n",
      "Copying artefacts from: not-best-disc-model\n",
      "Copying artefacts from: last-epoch-model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f064d67357f64fe4b416de0660d95e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35468 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724ed2dbe7144302b53e3617b58f9b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec509f2d44449c38f00559fc75c262b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1673e83943d43c9b68a1a3c5f9adef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bd017fb72042fdb12f1ba5fcb003b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba50e2f910da440e895767104f7ef2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abac1228d3a47ee98f503fec9092563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the sensitivity threshold...\n",
      "Using parallel computation!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08248e8f31444c2b97ee223b31a474ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap round:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity threshold summary:\n",
      "count    5.000000\n",
      "mean    -0.002576\n",
      "std      0.009959\n",
      "min     -0.018939\n",
      "25%     -0.003788\n",
      "50%     -0.000758\n",
      "75%      0.005303\n",
      "max      0.005303\n",
      "dtype: float64\n",
      "Sensitivity threshold: 0.0053030303030303025 qt_max: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4660fa7ef2af49028ff8a29af7548e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54dc3e88ce874cbab49c135f040f62ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n",
      "Critic round: 5,                     sensitivity_threshold: 0.0053030303030303025,                         val_sensitivity: -0.0241919191919192,                             val_sensitivities: [-0.025, -0.025, -0.025, -0.01893939393939394, -0.01893939393939394, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025]\n",
      "Copying artefacts from: best-disc-model\n",
      "Copying artefacts from: mean-best-disc-model\n",
      "Copying artefacts from: not-best-disc-model\n",
      "Copying artefacts from: last-epoch-model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f583673d5fdf4c3dac75a55d4fa334ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17940 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484f1760b5a74bca80d85938baa7c561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fbca36d6b44d7db721f27da699fd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5136c7229e2f43faaef01fccf1124153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ee5e4b740d49c0a145b6d8b54e6a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9423c5b1c0ee4dbbb3b7f79508e228e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e09d19ea34b4c67bcf861e411e0f183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the sensitivity threshold...\n",
      "Using parallel computation!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6402c543c540b5827f3a9142295ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap round:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity threshold summary:\n",
      "count    5.000000\n",
      "mean     0.003485\n",
      "std      0.026556\n",
      "min     -0.025000\n",
      "25%     -0.012879\n",
      "50%     -0.006818\n",
      "75%      0.023485\n",
      "max      0.038636\n",
      "dtype: float64\n",
      "Sensitivity threshold: 0.0356060606060606 qt_max: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8666bf9f9704a9eb04dd9bf0e06b5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acce629957fe49998f0c3cb4ab904c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n",
      "Critic round: 5,                     sensitivity_threshold: 0.0356060606060606,                         val_sensitivity: -0.0241919191919192,                             val_sensitivities: [-0.025, -0.025, -0.025, -0.01893939393939394, -0.01893939393939394, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025]\n",
      "Copying artefacts from: best-disc-model\n",
      "Copying artefacts from: mean-best-disc-model\n",
      "Copying artefacts from: not-best-disc-model\n",
      "Copying artefacts from: last-epoch-model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fd0b521c4e4ee1b3d541e93395548b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555057bc43514e6686533a5fc5b2b31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b3cf776b7a48b59588c6f7be8a97b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79657737915749f1b9a5611d5ab8d4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7024fb77d2420692fcf1d6910d025e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba6dba1298e44f9b40b918d391b6615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c16782ad36d4f92aab7580cf867a74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1936/1936 [04:43<00:00,  6.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1936/1936 [04:47<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the sensitivity threshold...\n",
      "Using parallel computation!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0081c18a4a2b4ebfbeebb2e0b2f556a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap round:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity threshold summary:\n",
      "count    5.000000\n",
      "mean     0.023485\n",
      "std      0.020215\n",
      "min     -0.000758\n",
      "25%      0.014394\n",
      "50%      0.020455\n",
      "75%      0.029545\n",
      "max      0.053788\n",
      "dtype: float64\n",
      "Sensitivity threshold: 0.048939393939393935 qt_max: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de55f22d0a0a43cb9d908ac692ded6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed14708777b43ce82d5c1ff9747e8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n",
      "Critic round: 5,                     sensitivity_threshold: 0.048939393939393935,                         val_sensitivity: -0.02217171717171717,                             val_sensitivities: [-0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.0068181818181818205, -0.025, -0.025, -0.025, -0.01893939393939394, -0.01893939393939394, -0.025, -0.01893939393939394, -0.01893939393939394]\n",
      "Copying artefacts from: best-disc-model\n",
      "Copying artefacts from: mean-best-disc-model\n",
      "Copying artefacts from: not-best-disc-model\n",
      "Copying artefacts from: last-epoch-model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab72a9bbcca94a689c62ccacc16f04f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2634bbf0fb0a44a68ec922f6461fb673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3677dbdf7b5c45b6bf5bc0fd56a60457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02d88f3c854422880348d68b7f5f3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa66b7d1efea4003ad83a1f07bcc6fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64b55bf21b24d35a4e61d97e03c80b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d2ec58688a4a1facd56f8a166149f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the sensitivity threshold...\n",
      "Using parallel computation!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa18a9c228684e37b32445bc4c0509e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap round:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity threshold summary:\n",
      "count    5.000000\n",
      "mean    -0.001970\n",
      "std      0.026985\n",
      "min     -0.025000\n",
      "25%     -0.012879\n",
      "50%     -0.009848\n",
      "75%     -0.006818\n",
      "max      0.044697\n",
      "dtype: float64\n",
      "Sensitivity threshold: 0.034393939393939386 qt_max: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ef069f4ac240c48a42b7cc5c33ec23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b1ba9e5fa54757a26083d24bef4baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n",
      "Critic round: 5,                     sensitivity_threshold: 0.034393939393939386,                         val_sensitivity: -0.02217171717171717,                             val_sensitivities: [-0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.0068181818181818205, -0.025, -0.025, -0.025, -0.01893939393939394, -0.01893939393939394, -0.025, -0.01893939393939394, -0.01893939393939394]\n",
      "Copying artefacts from: best-disc-model\n",
      "Copying artefacts from: mean-best-disc-model\n",
      "Copying artefacts from: not-best-disc-model\n",
      "Copying artefacts from: last-epoch-model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f7cf9362d443768615cf196a819539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22385 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9602c4f0af14d8eb3052108d631bb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046d3d41386245baa66828c9314597fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a191e6445ae94d949823d870b928af60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4633683af1e1420b8af79d183fc4a3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c50d22e1c94431386b8e359c33199ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4099ef1dc4446c297f80840209ac3b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 110\u001b[0m\n\u001b[0;32m    106\u001b[0m og_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m og_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(inv_age_map)\n\u001b[0;32m    107\u001b[0m og_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresidence\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m og_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresidence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(inv_residence_map)\n\u001b[1;32m--> 110\u001b[0m dcr\u001b[38;5;241m.\u001b[39msynthesize(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m    112\u001b[0m old_syn_1 \u001b[38;5;241m=\u001b[39m dcr\u001b[38;5;241m.\u001b[39msyn1\n\u001b[0;32m    113\u001b[0m old_syn_2 \u001b[38;5;241m=\u001b[39m dcr\u001b[38;5;241m.\u001b[39msyn2\n",
      "File \u001b[1;32m~\\Downloads\\Research\\KDD_GReaTER_submission\\Data_Clean_Room.py:169\u001b[0m, in \u001b[0;36mdata_clean_room.synthesize\u001b[1;34m(self, parent_synthetic_size, child_synthetic_size)\u001b[0m\n\u001b[0;32m    166\u001b[0m     child_samples\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m identifier\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parent_samples, child_samples\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderec_parent_syn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderec_child_1_syn \u001b[38;5;241m=\u001b[39m synthesize_with_rtf_1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderec_parent_small, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderec_child_1_small, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midentifier, parent_synthetic_size \u001b[38;5;241m=\u001b[39m parent_synthetic_size, child_synthetic_size \u001b[38;5;241m=\u001b[39m child_synthetic_size)\n\u001b[0;32m    170\u001b[0m dummy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderec_child_2_syn \u001b[38;5;241m=\u001b[39m synthesize_with_rtf_2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderec_parent_small, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderec_child_2_small, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midentifier, parent_synthetic_size \u001b[38;5;241m=\u001b[39m parent_synthetic_size, child_synthetic_size \u001b[38;5;241m=\u001b[39m child_synthetic_size)\n\u001b[0;32m    172\u001b[0m subset1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderec_parent_syn[[col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderec_parent_syn\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mog1\u001b[38;5;241m.\u001b[39mcolumns]]\n",
      "File \u001b[1;32m~\\Downloads\\Research\\KDD_GReaTER_submission\\Data_Clean_Room.py:113\u001b[0m, in \u001b[0;36mdata_clean_room.synthesize.<locals>.synthesize_with_rtf_1\u001b[1;34m(parent, child, identifier, parent_synthetic_size, child_synthetic_size)\u001b[0m\n\u001b[0;32m    110\u001b[0m parent_samples\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m join_on\n\u001b[0;32m    111\u001b[0m parent_samples \u001b[38;5;241m=\u001b[39m parent_samples\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m--> 113\u001b[0m child_samples \u001b[38;5;241m=\u001b[39m child_model_1\u001b[38;5;241m.\u001b[39msample(n_samples \u001b[38;5;241m=\u001b[39m child_synthetic_size,\n\u001b[0;32m    114\u001b[0m     input_unique_ids\u001b[38;5;241m=\u001b[39mparent_samples[join_on],\n\u001b[0;32m    115\u001b[0m     input_df\u001b[38;5;241m=\u001b[39mparent_samples\u001b[38;5;241m.\u001b[39mdrop(join_on, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    116\u001b[0m     output_max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    117\u001b[0m     gen_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    119\u001b[0m child_samples\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m identifier\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parent_samples, child_samples\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\realtabformer\\realtabformer.py:1290\u001b[0m, in \u001b[0;36mREaLTabFormer.sample\u001b[1;34m(self, n_samples, input_unique_ids, input_df, input_ids, gen_batch, device, seed_input, save_samples, constrain_tokens_gen, validator, continuous_empty_limit, suppress_tokens, forced_decoder_ids, related_num, **generate_kwargs)\u001b[0m\n\u001b[0;32m   1269\u001b[0m     relational_sampler \u001b[38;5;241m=\u001b[39m RelationalSampler\u001b[38;5;241m.\u001b[39msampler_from_model(\n\u001b[0;32m   1270\u001b[0m         rtf_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m   1271\u001b[0m     )\n\u001b[0;32m   1272\u001b[0m     \u001b[38;5;66;03m# (\u001b[39;00m\n\u001b[0;32m   1273\u001b[0m     \u001b[38;5;66;03m#     model_type=self.model_type,\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;66;03m#     model=self.model,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1287\u001b[0m     \u001b[38;5;66;03m#     device=device,\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m-> 1290\u001b[0m     synth_df \u001b[38;5;241m=\u001b[39m relational_sampler\u001b[38;5;241m.\u001b[39msample_relational(\n\u001b[0;32m   1291\u001b[0m         input_unique_ids\u001b[38;5;241m=\u001b[39minput_unique_ids,\n\u001b[0;32m   1292\u001b[0m         input_df\u001b[38;5;241m=\u001b[39minput_df,\n\u001b[0;32m   1293\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1294\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m   1295\u001b[0m         gen_batch\u001b[38;5;241m=\u001b[39mgen_batch,\n\u001b[0;32m   1296\u001b[0m         constrain_tokens_gen\u001b[38;5;241m=\u001b[39mconstrain_tokens_gen,\n\u001b[0;32m   1297\u001b[0m         validator\u001b[38;5;241m=\u001b[39mvalidator,\n\u001b[0;32m   1298\u001b[0m         continuous_empty_limit\u001b[38;5;241m=\u001b[39mcontinuous_empty_limit,\n\u001b[0;32m   1299\u001b[0m         suppress_tokens\u001b[38;5;241m=\u001b[39msuppress_tokens,\n\u001b[0;32m   1300\u001b[0m         forced_decoder_ids\u001b[38;5;241m=\u001b[39mforced_decoder_ids,\n\u001b[0;32m   1301\u001b[0m         related_num\u001b[38;5;241m=\u001b[39mrelated_num,\n\u001b[0;32m   1302\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs,\n\u001b[0;32m   1303\u001b[0m     )\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_samples:\n\u001b[0;32m   1306\u001b[0m     samples_fname \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples_save_dir\n\u001b[0;32m   1308\u001b[0m         \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrtf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-exp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-samples_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msynth_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1309\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\realtabformer\\rtf_sampler.py:944\u001b[0m, in \u001b[0;36mRelationalSampler.sample_relational\u001b[1;34m(self, input_unique_ids, input_df, input_ids, gen_batch, device, constrain_tokens_gen, validator, continuous_empty_limit, suppress_tokens, forced_decoder_ids, related_num, **generate_kwargs)\u001b[0m\n\u001b[0;32m    939\u001b[0m     samples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\n\u001b[0;32m    940\u001b[0m         (input_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    941\u001b[0m     )\n\u001b[0;32m    942\u001b[0m     samples \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken2id\u001b[39m\u001b[38;5;124m\"\u001b[39m][SpecialTokens\u001b[38;5;241m.\u001b[39mPAD]\n\u001b[1;32m--> 944\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _samples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_input_batch(\n\u001b[0;32m    945\u001b[0m     input_df\u001b[38;5;241m=\u001b[39minput_df,\n\u001b[0;32m    946\u001b[0m     gen_batch\u001b[38;5;241m=\u001b[39mgen_batch,\n\u001b[0;32m    947\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    948\u001b[0m     constrain_tokens_gen\u001b[38;5;241m=\u001b[39mconstrain_tokens_gen,\n\u001b[0;32m    949\u001b[0m     suppress_tokens\u001b[38;5;241m=\u001b[39msuppress_tokens,\n\u001b[0;32m    950\u001b[0m     forced_decoder_ids\u001b[38;5;241m=\u001b[39mforced_decoder_ids,\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs,\n\u001b[0;32m    952\u001b[0m ):\n\u001b[0;32m    953\u001b[0m     end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(_samples)\n\u001b[0;32m    955\u001b[0m     samples[start:end, : _samples\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m _samples\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\realtabformer\\rtf_sampler.py:1017\u001b[0m, in \u001b[0;36mRelationalSampler._sample_input_batch\u001b[1;34m(self, input_df, gen_batch, device, constrain_tokens_gen, suppress_tokens, forced_decoder_ids, **generate_kwargs)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(loader_iters):\n\u001b[0;32m   1015\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m-> 1017\u001b[0m     _samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1018\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m   1019\u001b[0m         as_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1020\u001b[0m         constrain_tokens_gen\u001b[38;5;241m=\u001b[39mconstrain_tokens_gen,\n\u001b[0;32m   1021\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;66;03m# num_return_sequences=gen_batch,\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m         do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1024\u001b[0m         forced_decoder_ids\u001b[38;5;241m=\u001b[39mforced_decoder_ids,\n\u001b[0;32m   1025\u001b[0m         suppress_tokens\u001b[38;5;241m=\u001b[39msuppress_tokens,\n\u001b[0;32m   1026\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs,\n\u001b[0;32m   1027\u001b[0m     )\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _samples\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\realtabformer\\rtf_sampler.py:247\u001b[0m, in \u001b[0;36mREaLSampler._generate\u001b[1;34m(self, device, as_numpy, constrain_tokens_gen, **generate_kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meos_token_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    245\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meos_token_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken2id\u001b[39m\u001b[38;5;124m\"\u001b[39m][SpecialTokens\u001b[38;5;241m.\u001b[39mEOS]\n\u001b[1;32m--> 247\u001b[0m _samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_numpy:\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:1914\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1906\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1907\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1908\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1909\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1910\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1911\u001b[0m     )\n\u001b[0;32m   1913\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   1915\u001b[0m         input_ids,\n\u001b[0;32m   1916\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1917\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[0;32m   1918\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1919\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   1920\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1921\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1922\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1923\u001b[0m     )\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   1927\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   1929\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1931\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:2651\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2648\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2650\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2651\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[0;32m   2652\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[0;32m   2653\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2654\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   2655\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   2656\u001b[0m )\n\u001b[0;32m   2658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2659\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\accelerate\\utils\\operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\accelerate\\utils\\operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:43\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[1;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:625\u001b[0m, in \u001b[0;36mEncoderDecoderModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_input_ids\u001b[38;5;241m.\u001b[39mnew_tensor(decoder_input_ids \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[1;32m--> 625\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[0;32m    626\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39mdecoder_input_ids,\n\u001b[0;32m    627\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mdecoder_attention_mask,\n\u001b[0;32m    628\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m    629\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    630\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39mdecoder_inputs_embeds,\n\u001b[0;32m    631\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    632\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    633\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    634\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    635\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_decoder,\n\u001b[0;32m    637\u001b[0m )\n\u001b[0;32m    639\u001b[0m \u001b[38;5;66;03m# Compute loss independent from decoder (as some shift the logits inside them)\u001b[39;00m\n\u001b[0;32m    640\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1421\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1419\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1421\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m   1422\u001b[0m     input_ids,\n\u001b[0;32m   1423\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1424\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1425\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   1426\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1427\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1428\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1429\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1430\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   1431\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1432\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1433\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1434\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1435\u001b[0m )\n\u001b[0;32m   1436\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1235\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1223\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1224\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1225\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1232\u001b[0m         output_attentions,\n\u001b[0;32m   1233\u001b[0m     )\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1235\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m block(\n\u001b[0;32m   1236\u001b[0m         hidden_states,\n\u001b[0;32m   1237\u001b[0m         layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[0;32m   1238\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1239\u001b[0m         head_mask\u001b[38;5;241m=\u001b[39mhead_mask[i],\n\u001b[0;32m   1240\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1241\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   1242\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1243\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1244\u001b[0m     )\n\u001b[0;32m   1246\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:742\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    740\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    741\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_cross_attn(hidden_states)\n\u001b[1;32m--> 742\u001b[0m cross_attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrossattention(\n\u001b[0;32m    743\u001b[0m     hidden_states,\n\u001b[0;32m    744\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    745\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    746\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m    747\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m    748\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    749\u001b[0m )\n\u001b[0;32m    750\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m cross_attn_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    751\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:346\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    344\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attn(query, key, value, attention_mask, head_mask)\n\u001b[0;32m    348\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_heads(attn_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[0;32m    349\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(attn_output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:198\u001b[0m, in \u001b[0;36mGPT2Attention._attn\u001b[1;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_attn\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, key, value, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, head_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 198\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(query, key\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_attn_weights:\n\u001b[0;32m    201\u001b[0m         attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull(\n\u001b[0;32m    202\u001b[0m             [], value\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mattn_weights\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mattn_weights\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    203\u001b[0m         )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "task_ids = [10005, 10006, 14584, 22100, 31941, 31996, 34382, 34975]\n",
    "\n",
    "for task_id in task_ids:\n",
    "    torch.cuda.empty_cache()\n",
    "    d1 = pd.read_csv(f\"datasets/task_id_{task_id}/feeds.csv\")\n",
    "    d2 = pd.read_csv(f\"datasets/task_id_{task_id}/ads.csv\")\n",
    "    \n",
    "    \n",
    "    if task_id == 10006 or task_id == 22100:\n",
    "        d2 = d2.drop('ad_close_list_v001', axis = 1)\n",
    "        d2 = d2.drop('ad_close_list_v002', axis = 1)\n",
    "        d2 = d2.drop('ad_close_list_v003', axis = 1)\n",
    "        d2 = d2.drop('pt_d', axis = 1)\n",
    "        d1 = d1.drop('e_et', axis = 1)\n",
    "    else:\n",
    "        d1 = convert_date_column(d1, 'e_et')\n",
    "        d2 = convert_date_column(d2, 'pt_d')\n",
    "\n",
    "    \n",
    "    # Create the mapping system manually \n",
    "    gender_map = {2: 'male', 3: 'female', 4: 'others'}\n",
    "    age_map = {}\n",
    "\n",
    "    for i in np.unique(d2['age']):\n",
    "        age_map[i] = f\"Age from {i}0 to {i}9\"\n",
    "\n",
    "\n",
    "    residence_list = ['US', 'China', 'Canada', 'Mexico', 'Japan', 'Korea', 'UK', 'France', 'Italy', 'Spain', 'Russua', 'India', 'Indonesia', 'Australia', 'Brazil', 'Argentina', 'Mexico', \n",
    "                      'Portugal', 'Sweden', 'Norway', 'Denmark', 'Finland', 'New Zealand', 'Cambodia', 'Thailand', 'Vietnam', 'Malaysia', 'Philippines', 'Jamaica', 'Egypt', 'Saudi Arabia', 'Iran', 'Israel', 'Kenya', 'Nigeria']\n",
    "\n",
    "    residence_map = {}\n",
    "    residence_pool = random.sample(residence_list, len(np.unique(d2['residence'])))\n",
    "    j = 0\n",
    "    for i in np.unique(d2['residence']):\n",
    "        residence_map[i] = residence_pool[j]\n",
    "        j += 1\n",
    "    \n",
    "    # Use map function to replace numeric values with categorical terms\n",
    "    d2['gender'] = d2['gender'].map(gender_map)\n",
    "    d2['age'] = d2['age'].map(age_map)\n",
    "    d2['residence'] = d2['residence'].map(residence_map)\n",
    "    \n",
    "    # Create the inverse mapping system to revert synthetic data\n",
    "    inv_gender_map = {v: k for k, v in gender_map.items()}\n",
    "    inv_residence_map = {v: k for k, v in residence_map.items()}\n",
    "    inv_age_map = {v: k for k, v in age_map.items()}\n",
    "    \n",
    "    \n",
    "    \n",
    "    if 'log_id' in d2.columns:\n",
    "        d2 = d2.drop('log_id', axis = 1)\n",
    "    \n",
    "    dcr = data_clean_room(d1, d2, 'user_id')\n",
    "    dcr.derec()\n",
    "    dcr.sampling(200)\n",
    "    \n",
    "    c1 = dcr.derec_child_1_small\n",
    "    c2 = dcr.derec_child_2_small\n",
    "    \n",
    "    # Extract the Parent Table with the DEREC pipeline \n",
    "    parent = dcr.derec_parent_small\n",
    "    \n",
    "    # Combine the remaining child tables with one of the correlation dimensional reduction method\n",
    "    child = cdr(c1, c2, 'user_id', 0.1)\n",
    "    #child = direct_combine(c1, c2, 'user_id')\n",
    "    #child = cdr_hierarchical_cluster(c1, c2, 'user_id')\n",
    "    \n",
    "    join_on = 'user_id'              \n",
    "        \n",
    "    # Synthesize data\n",
    "    parent_samples, child_samples = synthesize(parent, child, parent_n = 20, child_n = 200, join_on = join_on)\n",
    "    \n",
    "    # Refresh cuda memories\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Reverse the parent-child table structure back to input data structure\n",
    "    new_syn_child_1 = child_samples[[col for col in child_samples.columns if col in dcr.og1.columns]]\n",
    "    new_syn_child_2 = child_samples[[col for col in child_samples.columns if col in dcr.og2.columns]]\n",
    "    new_syn_parent_1 = parent_samples[[col for col in parent_samples.columns if col in dcr.og1.columns]]\n",
    "    new_syn_parent_2 = parent_samples[[col for col in parent_samples.columns if col in dcr.og2.columns]]\n",
    "    \n",
    "    new_syn_1 = pd.merge(new_syn_parent_1, new_syn_child_1, left_on = 'user_id', right_on = 'user_id')\n",
    "    new_syn_2 = pd.merge(new_syn_parent_2, new_syn_child_2, left_on = 'user_id', right_on = 'user_id')\n",
    "    \n",
    "\n",
    "    # Reverse map the categories to return to input data format\n",
    "    new_syn_2['gender'] = new_syn_2['gender'].map(inv_gender_map)\n",
    "    new_syn_2['age'] = new_syn_2['age'].map(inv_age_map)\n",
    "    new_syn_2['residence'] = new_syn_2['residence'].map(inv_residence_map)\n",
    "    \n",
    "    d2['gender'] = d2['gender'].map(inv_gender_map)\n",
    "    d2['age'] = d2['age'].map(inv_age_map)\n",
    "    d2['residence'] = d2['residence'].map(inv_residence_map)\n",
    "    \n",
    "    og_parent = dcr.derec_parent_small\n",
    "    og_1_p = og_parent[[col for col in parent_samples.columns if col in dcr.og1.columns]]\n",
    "    og_2_p = og_parent[[col for col in parent_samples.columns if col in dcr.og2.columns]]\n",
    "    \n",
    "    og_1 = pd.merge(og_1_p, c1, left_on = 'user_id', right_on = 'user_id')\n",
    "    og_2 = pd.merge(og_2_p, c2, left_on = 'user_id', right_on = 'user_id')\n",
    "    \n",
    "    og_1 = og_1[list(new_syn_1.columns)]\n",
    "    og_2 = og_2[list(new_syn_2.columns)]\n",
    "    \n",
    "    og_2['gender'] = og_2['gender'].map(inv_gender_map)\n",
    "    og_2['age'] = og_2['age'].map(inv_age_map)\n",
    "    og_2['residence'] = og_2['residence'].map(inv_residence_map)\n",
    "    \n",
    "    \n",
    "    dcr.synthesize(20, 200)\n",
    "    \n",
    "    old_syn_1 = dcr.syn1\n",
    "    old_syn_2 = dcr.syn2\n",
    "    \n",
    "    old_syn_1 = old_syn_1[list(new_syn_1.columns)]\n",
    "    old_syn_2 = old_syn_2[list(new_syn_2.columns)]\n",
    "        \n",
    "    old_syn_2['gender'] = old_syn_2['gender'].map(inv_gender_map)\n",
    "    old_syn_2['age'] = old_syn_2['age'].map(inv_age_map)\n",
    "    old_syn_2['residence'] = old_syn_2['residence'].map(inv_residence_map)    \n",
    "    \n",
    "    \n",
    "    if task_id != 10006 and task_id != 22100:\n",
    "        new_syn_1 = combine_date(new_syn_1, 'e_et')\n",
    "        new_syn_2 = combine_date(new_syn_2, 'pt_d')\n",
    "\n",
    "        old_syn_1 = combine_date(old_syn_1, 'e_et')\n",
    "        old_syn_2 = combine_date(old_syn_2, 'pt_d')\n",
    "\n",
    "        og_1 = combine_date(og_1, 'e_et')\n",
    "        og_2 = combine_date(og_2, 'pt_d')\n",
    "    \n",
    "    \n",
    "    og = {}\n",
    "    og['d1'] = og_1\n",
    "    og['d2'] = og_2\n",
    "    \n",
    "    old = {}\n",
    "    old['d1'] = old_syn_1\n",
    "    old['d2'] = old_syn_2\n",
    "    \n",
    "    new = {}\n",
    "    new['d1'] = new_syn_1\n",
    "    new['d2'] = new_syn_2\n",
    "    \n",
    "    old_evaluation = simpro(og, old)\n",
    "    old_evaluation.cal_marginal_indicators()\n",
    "    old_evaluation.cal_conditional_indicators()\n",
    "    \n",
    "    new_evaluation = simpro(og, new)\n",
    "    new_evaluation.cal_marginal_indicators()\n",
    "    new_evaluation.cal_conditional_indicators()\n",
    "    \n",
    "    old_p = old_evaluation.conditional_indicators['p-values']\n",
    "    new_p = new_evaluation.conditional_indicators['p-values']\n",
    "    old_w = old_evaluation.conditional_indicators['w-distance']\n",
    "    new_w = new_evaluation.conditional_indicators['w-distance']\n",
    "    \n",
    "    p_val = pd.DataFrame([old_p, new_p], index = ['Old', 'New']).T\n",
    "    p_val = p_val.fillna(1)\n",
    "    p_val.to_csv(f\"results/p_val_{task_id}_manual_mapping_reduction.csv\")\n",
    "    \n",
    "    w_dis = pd.DataFrame([old_w, new_w], index = ['Old', 'New']).T\n",
    "    w_dis.to_csv(f\"results/w_dis_{task_id}_manual_mapping_reduction.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ef42ea",
   "metadata": {},
   "source": [
    "# Convert '^' to ' and '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f1fca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_symbol_to_word(value, symbol = '^'):\n",
    "    if symbol in str(value):\n",
    "        return str(value).replace(symbol, \" and \")\n",
    "    else: return value\n",
    "    \n",
    "def inv_change_symbol_to_word(value, symbol = \" and \"):\n",
    "    if symbol in str(value):\n",
    "        return str(value).replace(symbol, \"^\")\n",
    "    else: return value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dda6010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the sensitivity threshold...\n",
      "Using parallel computation!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a302308df1e4495384cfa3ab94e05f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap round:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity threshold summary:\n",
      "count    5.000000\n",
      "mean     0.011364\n",
      "std      0.016735\n",
      "min     -0.003788\n",
      "25%     -0.000758\n",
      "50%      0.011364\n",
      "75%      0.011364\n",
      "max      0.038636\n",
      "dtype: float64\n",
      "Sensitivity threshold: 0.03318181818181817 qt_max: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac931849cb84990859e548c97e44598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a25998d9c14973a9b945dc07199707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n",
      "Critic round: 5,                     sensitivity_threshold: 0.03318181818181817,                         val_sensitivity: -0.018333333333333333,                             val_sensitivities: [-0.01893939393939394, -0.01893939393939394, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.01893939393939394, -0.01287878787878788, -0.01287878787878788, -0.01287878787878788, -0.025, -0.003787878787878789, -0.0007575757575757599]\n",
      "Copying artefacts from: best-disc-model\n",
      "Copying artefacts from: mean-best-disc-model\n",
      "Copying artefacts from: not-best-disc-model\n",
      "Copying artefacts from: last-epoch-model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e7c92a49a54d95ba33c846a11fc399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35468 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b67227cc3104145873c3bade9c12936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16569a61072c4e4bbc7e58b4be6950f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c49b121952f4940abae73a12b78475e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacc624bf69849b9b6a1aebd0b33d2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d664b162194f22a2fd9429824411c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9e1679e823498a8055a95864e2d49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the sensitivity threshold...\n",
      "Using parallel computation!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3077bd3e1546fb9e85c11f4028d0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap round:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity threshold summary:\n",
      "count    5.000000\n",
      "mean     0.033788\n",
      "std      0.046779\n",
      "min     -0.025000\n",
      "25%     -0.000758\n",
      "50%      0.050758\n",
      "75%      0.050758\n",
      "max      0.093182\n",
      "dtype: float64\n",
      "Sensitivity threshold: 0.08469696969696969 qt_max: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e74fa8f12024ca6a6b5e6840421b542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18077bc106fa43889f338772a883fa05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n",
      "Critic round: 5,                     sensitivity_threshold: 0.08469696969696969,                         val_sensitivity: -0.018333333333333333,                             val_sensitivities: [-0.01893939393939394, -0.01893939393939394, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.01893939393939394, -0.01287878787878788, -0.01287878787878788, -0.01287878787878788, -0.025, -0.003787878787878789, -0.0007575757575757599]\n",
      "Copying artefacts from: best-disc-model\n",
      "Copying artefacts from: mean-best-disc-model\n",
      "Copying artefacts from: not-best-disc-model\n",
      "Copying artefacts from: last-epoch-model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19e6995cb9b49f994479ff97d67c567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17940 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2edf02cbfc4346b363247c014ffff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e629a9588b4c24bd103194d607429b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f0870ba8b94da08df1747a29622d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe978bf24504f9591945866711e94e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ae6ec4f93247c1aa4e32a9a422939e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c07ad6329eb4ac392f0d1d9bcaefe96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the sensitivity threshold...\n",
      "Using parallel computation!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fcf4e3461a49e3b674399750b39bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap round:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity threshold summary:\n",
      "count    5.000000\n",
      "mean     0.030152\n",
      "std      0.020708\n",
      "min      0.011364\n",
      "25%      0.014394\n",
      "50%      0.026515\n",
      "75%      0.035606\n",
      "max      0.062879\n",
      "dtype: float64\n",
      "Sensitivity threshold: 0.05742424242424242 qt_max: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29807a6e6ae42ce9e92871d709bd192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388b346ff9e84158bd04dd506266c91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n",
      "Critic round: 5,                     sensitivity_threshold: 0.05742424242424242,                         val_sensitivity: -0.018333333333333333,                             val_sensitivities: [-0.01893939393939394, -0.01893939393939394, -0.025, -0.025, -0.025, -0.025, -0.025, -0.025, -0.01893939393939394, -0.01287878787878788, -0.01287878787878788, -0.01287878787878788, -0.025, -0.003787878787878789, -0.0007575757575757599]\n",
      "Copying artefacts from: best-disc-model\n",
      "Copying artefacts from: mean-best-disc-model\n",
      "Copying artefacts from: not-best-disc-model\n",
      "Copying artefacts from: last-epoch-model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd2bef33b114af3a235d8481d11177a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5fa94e9be14084a0cb717933729920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f235424eb294870a76ccd761140c70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7c57433cd247bbbbe9cafcd1d26e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da844b7eb714ec8904a736044f55027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 128 samples generated. Sampling efficiency is: 100.0000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b598d15bac7c464aa8e0fd26e10c259b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848b51f521fd4a519bebf354515d7335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1936/1936 [04:51<00:00,  6.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1936/1936 [04:51<00:00,  6.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m parent \u001b[38;5;241m=\u001b[39m dcr\u001b[38;5;241m.\u001b[39mderec_parent_small\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Combine the remaining child tables with one of the correlation dimensional reduction method\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m child \u001b[38;5;241m=\u001b[39m cdr(c1, c2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#child = direct_combine(c1, c2, 'user_id')\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#child = cdr_hierarchical_cluster(c1, c2, 'user_id')\u001b[39;00m\n\u001b[0;32m     47\u001b[0m join_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m              \n",
      "Cell \u001b[1;32mIn[23], line 46\u001b[0m, in \u001b[0;36mcdr\u001b[1;34m(c1, c2, key, corr)\u001b[0m\n\u001b[0;32m     44\u001b[0m     new_col \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(child[key]):\n\u001b[1;32m---> 46\u001b[0m         new_col\u001b[38;5;241m.\u001b[39mextend(independent_col[independent_col[key] \u001b[38;5;241m==\u001b[39m user_id][col]\u001b[38;5;241m.\u001b[39msample(child[key]\u001b[38;5;241m.\u001b[39mvalue_counts()[user_id], replace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     47\u001b[0m     child[col] \u001b[38;5;241m=\u001b[39m new_col\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m special_col:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:1010\u001b[0m, in \u001b[0;36mIndexOpsMixin.value_counts\u001b[1;34m(self, normalize, sort, ascending, bins, dropna)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue_counts\u001b[39m(\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    930\u001b[0m     dropna: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    931\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m    932\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;124;03m    Return a Series containing counts of unique values.\u001b[39;00m\n\u001b[0;32m    934\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;124;03m    Name: count, dtype: int64\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mvalue_counts_internal(\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1012\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   1013\u001b[0m         ascending\u001b[38;5;241m=\u001b[39mascending,\n\u001b[0;32m   1014\u001b[0m         normalize\u001b[38;5;241m=\u001b[39mnormalize,\n\u001b[0;32m   1015\u001b[0m         bins\u001b[38;5;241m=\u001b[39mbins,\n\u001b[0;32m   1016\u001b[0m         dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   1017\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:954\u001b[0m, in \u001b[0;36mvalue_counts_internal\u001b[1;34m(values, sort, ascending, normalize, bins, dropna)\u001b[0m\n\u001b[0;32m    951\u001b[0m         result \u001b[38;5;241m=\u001b[39m Series(counts, index\u001b[38;5;241m=\u001b[39midx, name\u001b[38;5;241m=\u001b[39mname, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort:\n\u001b[1;32m--> 954\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39mascending)\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[0;32m    957\u001b[0m     result \u001b[38;5;241m=\u001b[39m result \u001b[38;5;241m/\u001b[39m counts\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:3860\u001b[0m, in \u001b[0;36mSeries.sort_values\u001b[1;34m(self, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   3858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3859\u001b[0m     values_to_sort \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 3860\u001b[0m sorted_index \u001b[38;5;241m=\u001b[39m nargsort(values_to_sort, kind, \u001b[38;5;28mbool\u001b[39m(ascending), na_position)\n\u001b[0;32m   3862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_range_indexer(sorted_index, \u001b[38;5;28mlen\u001b[39m(sorted_index)):\n\u001b[0;32m   3863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\sorting.py:439\u001b[0m, in \u001b[0;36mnargsort\u001b[1;34m(items, kind, ascending, na_position, key, mask)\u001b[0m\n\u001b[0;32m    437\u001b[0m     non_nans \u001b[38;5;241m=\u001b[39m non_nans[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    438\u001b[0m     non_nan_idx \u001b[38;5;241m=\u001b[39m non_nan_idx[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 439\u001b[0m indexer \u001b[38;5;241m=\u001b[39m non_nan_idx[non_nans\u001b[38;5;241m.\u001b[39margsort(kind\u001b[38;5;241m=\u001b[39mkind)]\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ascending:\n\u001b[0;32m    441\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "task_ids = [10005, 10006, 14584, 22100, 31941, 31996, 34382, 34975]\n",
    "\n",
    "for task_id in task_ids:\n",
    "    torch.cuda.empty_cache()\n",
    "    d1 = pd.read_csv(f\"datasets/task_id_{task_id}/feeds.csv\")\n",
    "    d2 = pd.read_csv(f\"datasets/task_id_{task_id}/ads.csv\")\n",
    "    \n",
    "    if task_id == 10006 or task_id == 22100:\n",
    "        d2 = d2.drop('ad_close_list_v001', axis = 1)\n",
    "        d2 = d2.drop('ad_close_list_v002', axis = 1)\n",
    "        d2 = d2.drop('ad_close_list_v003', axis = 1)\n",
    "        d2 = d2.drop('pt_d', axis = 1)\n",
    "        d1 = d1.drop('e_et', axis = 1)\n",
    "    else:\n",
    "        d1 = convert_date_column(d1, 'e_et')\n",
    "        d2 = convert_date_column(d2, 'pt_d')\n",
    "    \n",
    "    col_to_change = ['u_newsCatInterests', 'u_newsCatDislike', 'u_newsCatInterestsST', 'u_click_ca2_news']\n",
    "\n",
    "\n",
    "    for col in col_to_change:\n",
    "        if col in d1.columns:\n",
    "            d1[col] = d1[col].apply(lambda x: change_symbol_to_word(x, symbol = '^'))\n",
    "        if col in d2.columns:\n",
    "            d2[col] = d2[col].apply(lambda x: change_symbol_to_word(x, symbol = '^'))\n",
    "\n",
    "    \n",
    "    \n",
    "    if 'log_id' in d2.columns:\n",
    "        d2 = d2.drop('log_id', axis = 1)\n",
    "    \n",
    "    dcr = data_clean_room(d1, d2, 'user_id')\n",
    "    dcr.derec()\n",
    "    dcr.sampling(200)\n",
    "    \n",
    "    c1 = dcr.derec_child_1_small\n",
    "    c2 = dcr.derec_child_2_small\n",
    "    \n",
    "    # Extract the Parent Table with the DEREC pipeline \n",
    "    parent = dcr.derec_parent_small\n",
    "    \n",
    "    # Combine the remaining child tables with one of the correlation dimensional reduction method\n",
    "    child = cdr(c1, c2, 'user_id', 0.1)\n",
    "    #child = direct_combine(c1, c2, 'user_id')\n",
    "    #child = cdr_hierarchical_cluster(c1, c2, 'user_id')\n",
    "    \n",
    "    join_on = 'user_id'              \n",
    "        \n",
    "    ###\n",
    "    parent_samples, child_samples = synthesize(parent, child, parent_n = 20, child_n = 200, join_on = join_on)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    new_syn_child_1 = child_samples[[col for col in child_samples.columns if col in dcr.og1.columns]]\n",
    "    new_syn_child_2 = child_samples[[col for col in child_samples.columns if col in dcr.og2.columns]]\n",
    "    new_syn_parent_1 = parent_samples[[col for col in parent_samples.columns if col in dcr.og1.columns]]\n",
    "    new_syn_parent_2 = parent_samples[[col for col in parent_samples.columns if col in dcr.og2.columns]]\n",
    "    \n",
    "    new_syn_1 = pd.merge(new_syn_parent_1, new_syn_child_1, left_on = 'user_id', right_on = 'user_id')\n",
    "    new_syn_2 = pd.merge(new_syn_parent_2, new_syn_child_2, left_on = 'user_id', right_on = 'user_id')\n",
    "    \n",
    "    og_parent = dcr.derec_parent_small\n",
    "    og_1_p = og_parent[[col for col in parent_samples.columns if col in dcr.og1.columns]]\n",
    "    og_2_p = og_parent[[col for col in parent_samples.columns if col in dcr.og2.columns]]\n",
    "    \n",
    "    og_1 = pd.merge(og_1_p, c1, left_on = 'user_id', right_on = 'user_id')\n",
    "    og_2 = pd.merge(og_2_p, c2, left_on = 'user_id', right_on = 'user_id')\n",
    "    \n",
    "    og_1 = og_1[list(new_syn_1.columns)]\n",
    "    og_2 = og_2[list(new_syn_2.columns)]\n",
    "    \n",
    "    \n",
    "    for col in col_to_change:\n",
    "        if col in new_syn_1.columns:\n",
    "            new_syn_1[col] = new_syn_1[col].apply(lambda x: inv_change_symbol_to_word(x, symbol = ' and '))\n",
    "        if col in new_syn_2.columns:\n",
    "            new_syn_2[col] = new_syn_2[col].apply(lambda x: inv_change_symbol_to_word(x, symbol = ' and '))\n",
    "        if col in og_1.columns:\n",
    "            og_1[col] = og_1[col].apply(lambda x: inv_change_symbol_to_word(x, symbol = ' and '))\n",
    "        if col in og_2.columns:\n",
    "            og_2[col] = og_2[col].apply(lambda x: inv_change_symbol_to_word(x, symbol = ' and '))\n",
    "        if col in d1.columns:\n",
    "            d1[col] = d1[col].apply(lambda x: inv_change_symbol_to_word(x, symbol = ' and '))\n",
    "        if col in d2.columns:\n",
    "            d2[col] = d2[col].apply(lambda x: inv_change_symbol_to_word(x, symbol = ' and '))\n",
    "    \n",
    "    dcr.synthesize(20, 200)\n",
    "    \n",
    "    old_syn_1 = dcr.syn1\n",
    "    old_syn_2 = dcr.syn2\n",
    "    \n",
    "    old_syn_1 = old_syn_1[list(new_syn_1.columns)]\n",
    "    old_syn_2 = old_syn_2[list(new_syn_2.columns)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if task_id != 10006 and task_id != 22100:\n",
    "        new_syn_1 = combine_date(new_syn_1, 'e_et')\n",
    "        new_syn_2 = combine_date(new_syn_2, 'pt_d')\n",
    "\n",
    "        old_syn_1 = combine_date(old_syn_1, 'e_et')\n",
    "        old_syn_2 = combine_date(old_syn_2, 'pt_d')\n",
    "\n",
    "        og_1 = combine_date(og_1, 'e_et')\n",
    "        og_2 = combine_date(og_2, 'pt_d')\n",
    "    \n",
    "    \n",
    "    og = {}\n",
    "    og['d1'] = og_1\n",
    "    og['d2'] = og_2\n",
    "    \n",
    "    old = {}\n",
    "    old['d1'] = old_syn_1\n",
    "    old['d2'] = old_syn_2\n",
    "    \n",
    "    new = {}\n",
    "    new['d1'] = new_syn_1\n",
    "    new['d2'] = new_syn_2\n",
    "    \n",
    "    old_evaluation = simpro(og, old)\n",
    "    old_evaluation.cal_marginal_indicators()\n",
    "    old_evaluation.cal_conditional_indicators()\n",
    "    \n",
    "    new_evaluation = simpro(og, new)\n",
    "    new_evaluation.cal_marginal_indicators()\n",
    "    new_evaluation.cal_conditional_indicators()\n",
    "    \n",
    "    old_p = old_evaluation.conditional_indicators['p-values']\n",
    "    new_p = new_evaluation.conditional_indicators['p-values']\n",
    "    old_w = old_evaluation.conditional_indicators['w-distance']\n",
    "    new_w = new_evaluation.conditional_indicators['w-distance']\n",
    "    \n",
    "    p_val = pd.DataFrame([old_p, new_p], index = ['Old', 'New']).T\n",
    "    p_val = p_val.fillna(1)\n",
    "    p_val.to_csv(f\"results/p_val_{task_id}_replace_special_symbol_reduction.csv\")\n",
    "    \n",
    "    w_dis = pd.DataFrame([old_w, new_w], index = ['Old', 'New']).T\n",
    "    w_dis.to_csv(f\"results/w_dis_{task_id}_replace_special_symbol_reduction.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0db8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
